{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddfdbda5-8477-4a09-9b99-72a17e619bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MessagePassing, radius_graph, knn_graph\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from torch_scatter.scatter import scatter\n",
    "from torch_scatter import scatter_min, scatter_max\n",
    "from torch_cluster import knn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_cluster import fps\n",
    "import pandas as pd\n",
    "from models.gpgin import ConvLayer, MLP\n",
    "from torch.nn.functional import silu\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptTensor,\n",
    "    SparseTensor,\n",
    "    pyg_lib,\n",
    "    torch_sparse,\n",
    ")\n",
    "from typing import Tuple, List, Dict, Union\n",
    "from pprint import pprint\n",
    "from torch_geometric.data import Data, DataListLoader, Dataset, InMemoryDataset, Batch\n",
    "from torch_geometric.loader import DataListLoader, DataLoader\n",
    "from torch_geometric.nn import *\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch, add_self_loops, remove_self_loops\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "import torch\n",
    "from torch import nn\n",
    "import rdkit\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import RDLogger\n",
    "\n",
    "from copy import deepcopy\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Tuple, List, Dict, Union\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import MessagePassing, radius_graph\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptTensor,\n",
    "    SparseTensor,\n",
    "    pyg_lib,\n",
    "    torch_sparse,\n",
    ")\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset,\n",
    "    download_url,\n",
    "    extract_zip,\n",
    ")\n",
    "from rdkit import Chem\n",
    "import os\n",
    "# Suppress RDKit warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "cuda=torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "import sascorer\n",
    "#torch.set_default_dtype(torch.float64)\n",
    "from models import *\n",
    "from rdkit.Chem.Crippen import MolLogP\n",
    "from typing import List\n",
    "from prolog import *\n",
    "import torchlens as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfec09b5-6547-4dc9-bcd8-9b6ba9c773e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingContext:\n",
    "    def __init__(self, cls, *args, **kwargs):\n",
    "        self.inner = cls(*args, **kwargs).to(cuda)\n",
    "        self.name = cls.__name__\n",
    "        self.optim = torch.optim.AdamW(self.inner.parameters())\n",
    "        self.sched = torch.optim.lr_scheduler.ExponentialLR(self.optim, gamma=0.98)\n",
    "        self.num_parameters = sum(map(torch.numel,self.inner.parameters()))\n",
    "        self.train_loss_record = dict()\n",
    "        self.test_loss_record = dict()\n",
    "        self.results = list()\n",
    "        self.total_iters = 0\n",
    "        self.running_loss = 0\n",
    "        self.best_eval_loss = 999999\n",
    "        self.stopped = False\n",
    "        self.batch_size=32\n",
    "        self.train_loss_metric='DotProductLoss'\n",
    "        self.eval_loss_metric='Multi-class Accuracy'\n",
    "        self.last_target_name='correct object class'\n",
    "        self.last_dataset_name='ModelNet40'\n",
    "        self.training=True\n",
    "    def save(self, prefix='saves'):\n",
    "        save_model(\n",
    "            self.name,\n",
    "            self.inner,\n",
    "            optimizer=self.optim,\n",
    "            scheduler=self.sched,\n",
    "            loss_record={\n",
    "                'train':self.train_loss_record,\n",
    "                'test':self.test_loss_record,\n",
    "            },\n",
    "            total_training_iters=self.total_iters,\n",
    "            last_batch_size=self.batch_size,\n",
    "            loss_metric={\n",
    "                'train':'MSE',\n",
    "                'test':'MAE',\n",
    "            },\n",
    "            last_target_name=self.last_target_name,\n",
    "            last_dataset_name=self.last_dataset_name\n",
    "        )\n",
    "    @classmethod\n",
    "    def load(cls, name, class_, prefix='saves', training=False, override=None):\n",
    "        if override is None:\n",
    "            override=dict()\n",
    "        checkpoint=torch.load(os.path.join(prefix,name,'checkpoint.pth'))\n",
    "        self=cls(class_,**dict(**checkpoint['config'],**override))\n",
    "        self.inner.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optim.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.total_iters=checkpoint['total_training_iters']\n",
    "        self.batch_size=checkpoint['last_batch_size']\n",
    "        self.train_loss_record=checkpoint['loss_record']['train']\n",
    "        self.test_loss_record=checkpoint['loss_record']['test']\n",
    "        self.best_eval_loss=min(self.test_loss_record.values())\n",
    "        self.training=training\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6903bfd-e32e-4918-9adb-c8751a2e178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def auto_save_hyperparams(init_fn):\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        # Bind the arguments to the function signature and apply defaults\n",
    "        sig = inspect.signature(init_fn)\n",
    "        bound_args = sig.bind(self, *args, **kwargs)\n",
    "        bound_args.apply_defaults()\n",
    "        # Save all parameters except 'self'\n",
    "        self.hparams = {\n",
    "            name: value \n",
    "            for name, value in bound_args.arguments.items() \n",
    "            if name != \"self\"\n",
    "        }\n",
    "        return init_fn(self, *args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3828419d-af83-4519-aee2-428c0b808825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def read_off_fast(path):\n",
    "    with open(path, 'r') as f:\n",
    "        if f.readline().strip() != 'OFF':\n",
    "            raise ValueError(f'Invalid OFF header: {path}')\n",
    "        n_verts, n_faces, _ = map(int, f.readline().strip().split())\n",
    "        data = np.loadtxt(f, max_rows=n_verts)  # FAST bulk load\n",
    "    return torch.from_numpy(data).float()\n",
    "\n",
    "class ModelNet40PyG(InMemoryDataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None, pre_transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.the_raw_dir = os.path.join(self.root_dir,'raw')\n",
    "        super().__init__(root_dir, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # Required but not used; raw data lives in category folders\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'modelnet40_{self.split}.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Assume files already downloaded/unzipped in root_dir\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        classes = sorted(os.listdir(self.the_raw_dir))\n",
    "        class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "        for cls in tqdm(classes, smoothing=0.0, dynamic_ncols=True):\n",
    "            split_dir = os.path.join(self.the_raw_dir, cls, self.split)\n",
    "            if not os.path.isdir(split_dir):\n",
    "                continue\n",
    "            label = class_to_idx[cls]\n",
    "            for fname in tqdm(os.listdir(split_dir), desc=cls, smoothing=0.0, dynamic_ncols=True):\n",
    "                if fname.endswith('.off'):\n",
    "                    path = os.path.join(split_dir, fname)\n",
    "                    pos = read_off_fast(path)  # (N, 3)\n",
    "                    data = Data(pos=pos, y=torch.tensor([label], dtype=torch.long))\n",
    "                    data_list.append(data)\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2680fefa-79f4-41a6-a702-8c7d015b23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ModelNet40PyG('./data/uncompressed/ModelNet40/', split='train')\n",
    "test = ModelNet40PyG('./data/uncompressed/ModelNet40/', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098bec3c-ca0a-4a13-b2af-a0c33a957380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_scatter import scatter_min\n",
    "from torch_geometric.nn import fps, knn\n",
    "from torch_geometric.nn.norm import GraphNorm\n",
    "from models.gpgin import GaussianSmearing, ConvLayer  # adjust import paths\n",
    "\n",
    "class DownSampler(nn.Module):\n",
    "    def __init__(self,\n",
    "                 ratio,\n",
    "                 mlp_dims_node, mlp_dims_edge,\n",
    "                 aggr='sum',\n",
    "                 node_norm=nn.LayerNorm, final_node_norm=nn.Identity,\n",
    "                 edge_norm=nn.LayerNorm, final_edge_norm=nn.Identity,\n",
    "                 activation=nn.SiLU, final_activation=nn.Identity,\n",
    "                 dropout_rate=0.1, final_dropout_rate=0.0,\n",
    "                 q=1,\n",
    "                 cutoff=10.0, max_neighbors=32):\n",
    "        super().__init__()\n",
    "        self.register_buffer('ratio', torch.tensor(ratio))\n",
    "        self.register_buffer('q',     torch.tensor(q))\n",
    "        # gaussian smear from 0→cutoff into edge_dims_edge[0] bins\n",
    "        self.gauss = GaussianSmearing(0.0, cutoff, mlp_dims_edge[0])\n",
    "        # message‐passing\n",
    "        self.conv = ConvLayer(\n",
    "            mlp_dims_node, mlp_dims_edge,\n",
    "            aggr=aggr,\n",
    "            node_norm=node_norm, final_node_norm=final_node_norm,\n",
    "            edge_norm=edge_norm, final_edge_norm=final_edge_norm,\n",
    "            activation=activation, final_activation=final_activation,\n",
    "            dropout_rate=dropout_rate, final_dropout_rate=final_dropout_rate,\n",
    "        )\n",
    "        # graph‐norm + residual‐scaling\n",
    "        self.norm = GraphNorm(mlp_dims_node[-1])\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.8))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv.reset_parameters()\n",
    "        nn.init.constant_(self.alpha, 0.8)\n",
    "\n",
    "    def forward(self, K, V, batch=None, dK_scale=1.0,\n",
    "                target_points=None, edge_index=None, sampled_idx=None):\n",
    "        N = K.size(0)\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(N, device=K.device, dtype=torch.long)\n",
    "\n",
    "        # --- sample points if needed ---\n",
    "        if sampled_idx is None:\n",
    "            sampled_idx = fps(K, ratio=self.ratio, batch=batch, random_start=True)\n",
    "            # ensure at least one neighbor per sampled node\n",
    "            edge_idx = knn(K[sampled_idx], K, 1,\n",
    "                           batch_x=batch[sampled_idx], batch_y=batch).flip(0)\n",
    "            _, sampled_idx = scatter_min(torch.rand(edge_idx.size(1), device=K.device),\n",
    "                                         edge_idx[0], dim=0)\n",
    "            sampled_idx = sampled_idx[(sampled_idx<K.shape[0])]\n",
    "        # --- compute effective k and kNN graph ---\n",
    "        q = int(self.q.item())\n",
    "        k_eff = max(1, min(q, N))\n",
    "        edge_index = knn(\n",
    "            K[sampled_idx], K, k_eff,\n",
    "            batch_x=batch[sampled_idx], batch_y=batch\n",
    "        )\n",
    "\n",
    "        src, tgt = edge_index\n",
    "        # raw distances\n",
    "        dists = (K[sampled_idx][tgt] - K[src]).norm(dim=-1)\n",
    "        # gaussian‐smeared edge features\n",
    "        edge_attr = self.gauss(dists)  # [E, edge_dim_0]\n",
    "        # message‐passing\n",
    "        h_old = V[sampled_idx]\n",
    "        h_target = (torch.zeros_like(h_old)\n",
    "                    if target_points is None else target_points)\n",
    "        #/print(\"   V:\",V.shape,V.std())\n",
    "        #/print(\"   h_target:\",h_target.shape,h_target.std())\n",
    "        #/print(\"   edge_index:\",edge_index.shape)\n",
    "        #/print(\"   edge_attr:\",edge_attr.shape, edge_attr.std())\n",
    "        Δh = self.conv((V, h_target), edge_index, edge_attr * dK_scale)\n",
    "        #/print(\"   Δh:\",Δh.shape,Δh.std())\n",
    "        return (K[sampled_idx],\n",
    "                Δh,\n",
    "                batch[sampled_idx],\n",
    "                edge_index,\n",
    "                sampled_idx)\n",
    "\n",
    "\n",
    "class UpSampler(nn.Module):\n",
    "    def __init__(self,\n",
    "                 mlp_dims_node, mlp_dims_edge,\n",
    "                 aggr='sum',\n",
    "                 node_norm=nn.LayerNorm, final_node_norm=nn.Identity,\n",
    "                 edge_norm=nn.LayerNorm, final_edge_norm=nn.Identity,\n",
    "                 activation=nn.SiLU, final_activation=nn.Identity,\n",
    "                 dropout_rate=0.1, final_dropout_rate=0.0,\n",
    "                 cutoff=10.0, max_neighbors=32):\n",
    "        super().__init__()\n",
    "        self.conv = ConvLayer(\n",
    "            mlp_dims_node, mlp_dims_edge,\n",
    "            aggr=aggr,\n",
    "            node_norm=node_norm, final_node_norm=final_node_norm,\n",
    "            edge_norm=edge_norm, final_edge_norm=final_edge_norm,\n",
    "            activation=activation, final_activation=final_activation,\n",
    "            dropout_rate=dropout_rate, final_dropout_rate=final_dropout_rate,\n",
    "        )\n",
    "        self.gauss = GaussianSmearing(0.0, cutoff, mlp_dims_edge[0])\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.8))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv.reset_parameters()\n",
    "        nn.init.constant_(self.alpha, 0.8)\n",
    "\n",
    "    def forward(self, K_low, K_high, V_low, V_high, edge_index, dK_scale=1.0):\n",
    "        # reverse edge_index so src→tgt is low→high\n",
    "        tgt, src = edge_index.flip(0)\n",
    "        dists = (K_high[tgt] - K_low[src]).norm(dim=-1)\n",
    "        edge_attr = self.gauss(dists) * dK_scale\n",
    "\n",
    "        h_old = V_low\n",
    "        Δh = self.conv((V_high, V_low), edge_index.flip(0), edge_attr)\n",
    "\n",
    "\n",
    "        return Δh\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, ratios,\n",
    "                 mlp_dims_node, mlp_dims_edge,\n",
    "                 aggr='sum',\n",
    "                 node_norm=nn.LayerNorm, final_node_norm=nn.Identity,\n",
    "                 edge_norm=nn.LayerNorm, final_edge_norm=nn.Identity,\n",
    "                 activation=nn.SiLU, final_activation=nn.Identity,\n",
    "                 dropout_rate=0.1, final_dropout_rate=0.0,\n",
    "                 q=1, k_dim=2, cutoff=10.0, max_neighbors=32):\n",
    "        super().__init__()\n",
    "        self.k_dim = k_dim\n",
    "        self.activation = activation()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups   = nn.ModuleList()\n",
    "        self.down_norms = nn.ModuleList()\n",
    "        self.up_norms = nn.ModuleList()\n",
    "        for ratio in ratios:\n",
    "            self.downs.append(DownSampler(\n",
    "                ratio,\n",
    "                mlp_dims_node, mlp_dims_edge,\n",
    "                aggr, node_norm, final_node_norm,\n",
    "                edge_norm, final_edge_norm,\n",
    "                activation, final_activation,\n",
    "                dropout_rate, final_dropout_rate,\n",
    "                q, cutoff, max_neighbors\n",
    "            ))\n",
    "            self.ups.append(UpSampler(\n",
    "                mlp_dims_node, mlp_dims_edge,\n",
    "                aggr, node_norm, final_node_norm,\n",
    "                edge_norm, final_edge_norm,\n",
    "                activation, final_activation,\n",
    "                dropout_rate, final_dropout_rate,\n",
    "                cutoff, max_neighbors\n",
    "            ))\n",
    "        self.reset_parameters()\n",
    "        for _ in self.ups:\n",
    "            self.down_norms.append(GraphNorm(mlp_dims_node[-1]))\n",
    "        for _ in self.downs:\n",
    "            self.up_norms.append(GraphNorm(mlp_dims_node[-1]))\n",
    "    def reset_parameters(self):\n",
    "        for d in self.downs: d.reset_parameters()\n",
    "        for u in self.ups:   u.reset_parameters()\n",
    "\n",
    "    def forward(self, K, V, batch=None, history=None, is_last=False):\n",
    "        # identical logic as before, but uses the new DownSampler/UpSampler\n",
    "        if history is None:\n",
    "            history = [[None,]*5 for _ in range(1+len(self.downs))]\n",
    "            history[0] = [K, V, batch, None, None]\n",
    "        dK_scale = torch.tensor(1.0, device=K.device)\n",
    "        # DOWN\n",
    "        for i, (down, norm) in enumerate(zip(self.downs, self.down_norms)):\n",
    "            #/print(\"  UNet down...\")\n",
    "            _, target_points, _, edge_index, sampled_idx = history[i+1]\n",
    "            K, V_, batch, edge_index, sampled_idx = down(\n",
    "                K, V, batch,\n",
    "                dK_scale=dK_scale,\n",
    "                target_points=target_points,\n",
    "                edge_index=edge_index,\n",
    "                sampled_idx=sampled_idx\n",
    "            )\n",
    "            \n",
    "            #/print(\"  down norm V_/std:\",V_.shape,'/',V.std())\n",
    "            V_=norm(V_,batch)\n",
    "            V_=self.activation(V_)\n",
    "            if target_points is not None:\n",
    "                V =target_points+down.alpha*V_\n",
    "            else:\n",
    "                V = V_\n",
    "            history[i+1] = [K, V, batch, edge_index, sampled_idx]\n",
    "            dK_scale = dK_scale * (down.ratio).pow(1/self.k_dim)\n",
    "        #if is_last:\n",
    "        #    return V, None\n",
    "        # UP\n",
    "        j=len(self.downs)\n",
    "        for up, down, norm in zip(\n",
    "                self.ups, reversed(self.downs), self.up_norms\n",
    "        ):\n",
    "            #/print(\"  UNet up...\")\n",
    "            # #/print(\"up conv...\")\n",
    "            ##/print(\"Kh:\",Kh.shape)\n",
    "            ##/print(\"Vh:\",Vh.shape)\n",
    "            assert j!=0, \"j should never be 0 in this case\"\n",
    "            (Kh, Vh, bh, eih, _) = history[j-1]\n",
    "            dK_scale = dK_scale * (down.ratio).pow(-1/self.k_dim)\n",
    "            V_ = up(Kh, K, Vh, V, edge_index, dK_scale=dK_scale)\n",
    "            if j>1 or not is_last:\n",
    "                # #/print(\"up norm V_ bh:\",V_.shape,bh.shape)\n",
    "                V_=norm(V_,bh)\n",
    "                V_=self.activation(V_)\n",
    "            # #/print(\"Vh:\",Vh.shape)\n",
    "            # #/print(\"V_:\",V_.shape)\n",
    "            V =Vh+up.alpha*V_\n",
    "            # #/print(\"history[j-1][1]:\",type(history[j-1][1]))\n",
    "            history[j-1][1]=V\n",
    "            K, edge_index = Kh, eih\n",
    "            j=j-1\n",
    "\n",
    "        return V, history\n",
    "\n",
    "class PointCloudClassifier(nn.Module):\n",
    "    @auto_save_hyperparams\n",
    "    def __init__(self,\n",
    "            domain_dim,\n",
    "            raw_feature_dim,\n",
    "            latent_feature_dim,\n",
    "            ratios,\n",
    "            mlp_dims_node: List[int],\n",
    "            mlp_dims_edge: List[int],\n",
    "            \n",
    "            aggr: str = 'sum',\n",
    "            \n",
    "            node_norm=nn.LayerNorm, \n",
    "            final_node_norm=nn.Identity, \n",
    "            \n",
    "            edge_norm=nn.LayerNorm,\n",
    "            final_edge_norm=nn.Identity, \n",
    "            \n",
    "            activation=nn.SiLU, \n",
    "            final_activation=nn.Identity, \n",
    "            \n",
    "            dropout_rate=0.1, \n",
    "            final_dropout_rate=0.0,\n",
    "\n",
    "            q=1,\n",
    "            n_encoders=3,\n",
    "            ):\n",
    "        super().__init__()\n",
    "        assert mlp_dims_node[0]==mlp_dims_node[-1]==mlp_dims_edge[-1]==latent_feature_dim\n",
    "        self.latent_feature_dim=latent_feature_dim\n",
    "        #self.atom_emb = nn.Embedding(200, latent_feature_dim)\n",
    "        self.unets=nn.ModuleList([])\n",
    "        for _ in range(n_encoders):\n",
    "            unet=UNet(\n",
    "                    ratios=ratios,\n",
    "                    mlp_dims_node=mlp_dims_node,\n",
    "                    mlp_dims_edge=mlp_dims_edge,\n",
    "                    aggr=aggr,\n",
    "                    node_norm=node_norm,\n",
    "                    final_node_norm=final_node_norm,\n",
    "                    edge_norm=edge_norm,\n",
    "                    final_edge_norm=final_edge_norm,\n",
    "                    activation=activation,\n",
    "                    final_activation=final_activation,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    final_dropout_rate=final_dropout_rate,\n",
    "                    q=q,\n",
    "                    k_dim=domain_dim,\n",
    "            )\n",
    "            self.unets.append(unet)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        for unet in self.unets:\n",
    "            unet.reset_parameters()\n",
    "        \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "        \n",
    "    def get_config(self):\n",
    "        return self.hparams\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self._forward(data.pos,data.batch)\n",
    "    \n",
    "    def _forward(self, K, batch=None):\n",
    "        #K: float [N, 3] -> position\n",
    "        #batch: int [N] -> minibatch id\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(K.shape[0],dtype=torch.long,device=K.device)\n",
    "        assert batch.dtype == torch.long\n",
    "        assert batch.dim() == 1\n",
    "        assert batch.min() >= 0\n",
    "        if K.shape[0]>2000:#if point cloud is too big, subsample it uniformly\n",
    "            # print(\"K:\",K.shape,K.min().item(),'->',K.max().item())#K: torch.Size([2755, 3]) -73.44438171386719 -> 73.44438171386719\n",
    "            # print(\"batch:\",batch.shape,batch.min().item(),'->',batch.max().item())#batch: torch.Size([2755]) 0 -> 1\n",
    "\n",
    "            sampled_idx = fps(K, ratio=1024/K.shape[0], batch=batch, random_start=True)#sample 1024 points, the dataset is raw ModelNet40 .off files\n",
    "            # print(\"older sampled_idx:\",sampled_idx.shape,sampled_idx.min().item(),'->',sampled_idx.max().item())\n",
    "            #older sampled_idx: torch.Size([1025]) 0 -> 2754\n",
    "\n",
    "\n",
    "            assert sampled_idx.max().item() < K.shape[0]\n",
    "            assert sampled_idx.max().item() < batch.shape[0]\n",
    "            assert sampled_idx.min().item() >= 0\n",
    "            assert sampled_idx.numel() > 0\n",
    "            # ensure at least one neighbor per sampled node\n",
    "            edge_idx = knn(K[sampled_idx], K, 1,\n",
    "                           batch_x=batch[sampled_idx], batch_y=batch).flip(0)\n",
    "            #for each point, find the closest sampled point\n",
    "            #note: knn returns tgt, src (so edge_idx is flipped over the 0th axis to get src, tgt)\n",
    "            #edge_idx: torch.Size([2, 2755]) 0 -> 2754\n",
    "            tmp = torch.rand(edge_idx.size(1), device=K.device)\n",
    "            # print(\"tmp:\",tmp.shape,tmp.min().item(),'->',tmp.max().item())\n",
    "            # print(\"edge_idx.size(0):\",edge_idx.size(0))\n",
    "            # print(\"edge_idx.size(1):\",edge_idx.size(1))\n",
    "            # print(\"tmp.size(0):\",tmp.size(0))\n",
    "            # print(\"tmp:\",tmp)\n",
    "            # print(\"edge_idx[0]:\",edge_idx[0])\n",
    "            _, sampled_idx = scatter_min(tmp,\n",
    "                                         edge_idx[0], dim=0)# for each sampled point, pick a random point from all points whose closest sampled point is itself. this is to fight the edge-bias in FPS sampling\n",
    "            #so, edge_idx[0] has ~1024 unique entries while edge_idx[1] has K.shape[0] unique entries, this means\n",
    "            #that edge_idx[0] is not contiguouos: it can be like [0,1,2,5,6,7], where indeces 3 and 4 does not exists\n",
    "            #this leads the sampled_idx, to return sentinel bad values (like -1 or MAXVAL+1)\n",
    "            #so, we further map newer_sampled_idx to be edge_idx\n",
    "            sampled_idx = sampled_idx[(sampled_idx<K.shape[0])]#&(0<=sampled_idx)\n",
    "            # print(\"edge_idx:\",edge_idx.shape,edge_idx.min().item(),'->',edge_idx.max().item())\n",
    "            # print(\"newer sampled_idx:\",sampled_idx.shape,sampled_idx.min().item(),'->',sampled_idx.max().item())\n",
    "            #newer sampled_idx: torch.Size([1025]) 0 -> 2755\n",
    "            #assert raised, because newer sampled_idx's max is 2755\n",
    "            assert sampled_idx.max().item() < K.shape[0]\n",
    "            assert sampled_idx.max().item() < batch.shape[0]\n",
    "            assert sampled_idx.min().item() >= 0\n",
    "            assert sampled_idx.numel() > 0\n",
    "\n",
    "\n",
    "            K=K[sampled_idx]\n",
    "            batch=batch[sampled_idx]\n",
    "        #/print(\"PointCloudClassifier a\")\n",
    "        V=torch.zeros(K.shape[0],self.latent_feature_dim,device=K.device)#self.atom_emb(V)\n",
    "        #/print(\"PointCloudClassifier V:\",V.shape)\n",
    "        history=None\n",
    "        for i in range(len(self.unets)):\n",
    "            unet=self.unets[i]\n",
    "            is_last = (i==len(self.unets)-1)\n",
    "            V,history = unet(K, V, batch, history=history, is_last=is_last)\n",
    "            #/print(\" PointCloudClassifier V:\",V.shape,'std:',V.std())\n",
    "        V=scatter(V, batch, dim=0, reduce='mean')#.mean(-1)\n",
    "        return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4da31a5-98a2-43c2-8c26-555e195907dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "models=[]\n",
    "models=[]\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "773cead2-931d-46c9-84b8-d23930694bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53384"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM=1#scalar l norms\n",
    "EDGE_DIM=32\n",
    "EMB_DIM=32\n",
    "HDIM=32\n",
    "models.append(TrainingContext(PointCloudClassifier,\n",
    "    INPUT_DIM,EMB_DIM,HDIM,\n",
    "    [.1,.25,.25,.25],#downsample ratios\n",
    "    [HDIM,HDIM,HDIM],\n",
    "    [EDGE_DIM,HDIM*2,HDIM],#edge\n",
    "    q=5,\n",
    "    n_encoders=1,\n",
    "    activation=nn.ReLU\n",
    "    ))\n",
    "model=models[-1].inner.cuda()\n",
    "models[-1].num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2822763c-e4ea-4a6d-8b87-ead4bd38dfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178128692 18096.99197399167\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train, batch_size=32, shuffle=True)\n",
    "count=0\n",
    "total=0\n",
    "for batch in train_loader:\n",
    "    total+=(batch.pos.shape[0])\n",
    "    count+=batch.y.shape[0]\n",
    "print(total,total/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bfd864b-24e6-472d-b722-bf2cc0470d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd15daac225448f9a388b4aa75caeb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                         | 0/9843 [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=0\n",
    "for e in tqdm(train,smoothing=0.0,dynamic_ncols=True):\n",
    "    with torch.no_grad():\n",
    "        out=model(e.cuda())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "363de974-8797-413f-844d-9fa879bed8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2929ac2b9444025b5e4203ed3d170aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                         | 0/9843 [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = DataLoader(train, batch_size=1, shuffle=False)\n",
    "j=0\n",
    "for batch in tqdm(train_loader,smoothing=0.0,dynamic_ncols=True):\n",
    "    with torch.no_grad():\n",
    "        out=model(batch.cuda())\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fe3f95f-2b4c-49ea-b887-17dfc0a6e40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2755\n",
      "0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000011111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n"
     ]
    }
   ],
   "source": [
    "s=''.join(map(str,map(int,batch.batch.cpu())))\n",
    "print(len(s))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6690173-2e82-488a-b7e9-b80c421605b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43d12682ec24cd0bf6331081366ef82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                      | 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = DataLoader(train, batch_size=2, shuffle=False)\n",
    "j=0\n",
    "for batch in tqdm(train_loader,smoothing=0.0,dynamic_ncols=True):\n",
    "    if j>1760:\n",
    "        with torch.no_grad():\n",
    "            out=model(batch.cuda())\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d5c615-02d6-44e8-8804-628c0979db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch=batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da553d37-f778-4749-8ea6-921fcfbbfe09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(y=[2], pos=[2755, 3], batch=[2755], ptr=[3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b01ee10-2553-4ae8-8516-7864d0874b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: torch.Size([2755, 3]) -73.44438171386719 -> 73.44438171386719\n",
      "batch: torch.Size([2755]) 0 -> 1\n",
      "older sampled_idx: torch.Size([1025]) 0 -> 2754\n",
      "rand_tmp: torch.Size([2755]) 2.0749750547111034e-05 -> 0.9999164342880249\n",
      "edge_idx.size(0): 2\n",
      "edge_idx.size(1): 2755\n",
      "rand_tmp.size(0): 2755\n",
      "rand_tmp: tensor([0.2651, 0.9313, 0.7658,  ..., 0.3116, 0.4726, 0.2564], device='cuda:0')\n",
      "edge_idx[0]: tensor([ 14,   3,   1,  ..., 991, 989, 890], device='cuda:0')\n",
      "val: torch.Size([1025]) 0.0 -> 0.9908497929573059\n",
      "edge_idx: torch.Size([2, 2755]) 0 -> 2754\n",
      "newer_sampled_idx: torch.Size([1025]) 8 -> 2755\n",
      "final_sampled_idx: torch.Size([929]) 0 -> 1024\n"
     ]
    }
   ],
   "source": [
    "K=_batch.pos\n",
    "batch=_batch.batch\n",
    "if batch is None:\n",
    "    batch = torch.zeros(K.shape[0],dtype=torch.long,device=K.device)\n",
    "assert batch.dtype == torch.long\n",
    "assert batch.dim() == 1\n",
    "assert batch.min() >= 0\n",
    "if K.shape[0]>2000:#if point cloud is too big, subsample it uniformly\n",
    "    print(\"K:\",K.shape,K.min().item(),'->',K.max().item())#K: torch.Size([2755, 3]) -73.44438171386719 -> 73.44438171386719\n",
    "    print(\"batch:\",batch.shape,batch.min().item(),'->',batch.max().item())#batch: torch.Size([2755]) 0 -> 1\n",
    "    # K: torch.Size([2755, 3]) -73.44438171386719 -> 73.44438171386719\n",
    "    # batch: torch.Size([2755]) 0 -> 1\n",
    "    sampled_idx = fps(K, ratio=1024/K.shape[0], batch=batch, random_start=True)#sample 1024 points, the dataset is raw ModelNet40 .off files\n",
    "    print(\"older sampled_idx:\",sampled_idx.shape,sampled_idx.min().item(),'->',sampled_idx.max().item())\n",
    "    # older sampled_idx: torch.Size([1025]) 0 -> 2754\n",
    "    \n",
    "\n",
    "    assert sampled_idx.max().item() < K.shape[0]\n",
    "    assert sampled_idx.max().item() < batch.shape[0]\n",
    "    assert sampled_idx.min().item() >= 0\n",
    "    assert sampled_idx.numel() > 0\n",
    "    # ensure at least one neighbor per sampled node\n",
    "    edge_idx = knn(K[sampled_idx], K, 1,\n",
    "                   batch_x=batch[sampled_idx], batch_y=batch).flip(0)\n",
    "    #for each point, find the closest sampled point\n",
    "    #note: knn returns tgt, src (so edge_idx is flipped over the 0th axis to get src, tgt)\n",
    "    #edge_idx: torch.Size([2, 2755]) 0 -> 2754\n",
    "    rand_tmp = torch.rand(edge_idx.size(1), device=K.device)\n",
    "    print(\"rand_tmp:\",rand_tmp.shape,rand_tmp.min().item(),'->',rand_tmp.max().item())\n",
    "    print(\"edge_idx.size(0):\",edge_idx.size(0))\n",
    "    print(\"edge_idx.size(1):\",edge_idx.size(1))\n",
    "    print(\"rand_tmp.size(0):\",rand_tmp.size(0))\n",
    "    print(\"rand_tmp:\",rand_tmp)\n",
    "    print(\"edge_idx[0]:\",edge_idx[0])\n",
    "    # rand_tmp: torch.Size([2755]) 9.066204074770212e-05 -> 0.9996086359024048\n",
    "    # edge_idx.size(0): 2\n",
    "    # edge_idx.size(1): 2755\n",
    "    # rand_tmp.size(0): 2755\n",
    "    # rand_tmp: tensor([0.0268, 0.2423, 0.6176,  ..., 0.8445, 0.4571, 0.3178], device='cuda:0')\n",
    "    # edge_idx[0]: tensor([  1,   4,   7,  ..., 991, 987, 864], device='cuda:0')\n",
    "    _, newer_sampled_idx = scatter_min(rand_tmp,\n",
    "                                 edge_idx[0], dim=0)# for each sampled point, pick a random point from all points whose closest sampled point is itself. this is to fight the edge-bias in FPS sampling\n",
    "    final_sampled_idx = edge_idx[0][newer_sampled_idx[newer_sampled_idx<edge_idx.shape[1]]]\n",
    "    print(\"val:\",val.shape,val.min().item(),'->',val.max().item())\n",
    "    print(\"edge_idx:\",edge_idx.shape,edge_idx.min().item(),'->',edge_idx.max().item())\n",
    "    print(\"newer_sampled_idx:\",newer_sampled_idx.shape,newer_sampled_idx.min().item(),'->',newer_sampled_idx.max().item())\n",
    "    print(\"final_sampled_idx:\",final_sampled_idx.shape,final_sampled_idx.min().item(),'->',final_sampled_idx.max().item())\n",
    "    #val: torch.Size([1025]) 0.0 -> 0.9908497929573059 \n",
    "    #edge_idx: torch.Size([2, 2755]) 0 -> 2754 \n",
    "    #newer_sampled_idx: torch.Size([1025]) 0 -> 2755 problem is here, how is the argmin output of scatter_min larger than both its args' 0th dim (in 0-indexing-speak)?\n",
    "    \n",
    "    assert final_sampled_idx.max().item() < K.shape[0]\n",
    "    #^assert raised, because newer newer_sampled_idx's max is 2755\n",
    "    assert final_sampled_idx.max().item() < batch.shape[0]\n",
    "    assert final_sampled_idx.min().item() >= 0\n",
    "    assert final_sampled_idx.numel() > 0\n",
    "\n",
    "\n",
    "    K=K[final_sampled_idx]\n",
    "    batch=batch[final_sampled_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51f04039-f5b8-4d65-a2ce-53bf23b30f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp: torch.Size([929]) 8 -> 2752\n"
     ]
    }
   ],
   "source": [
    "tmp=newer_sampled_idx[(0<=newer_sampled_idx)&(newer_sampled_idx<edge_idx.shape[1])]\n",
    "print(\"tmp:\",tmp.shape,tmp.min().item(),'->',tmp.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2842e70d-4681-400a-a40c-3cb75d3e44a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2755, device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newer_sampled_idx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e99b4e9d-a620-4435-a7b5-20c09e1885a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2755])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b33bde5-14fb-46e3-8ac6-21c2c35d33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tmp=pd.Series(scatter_min(rand_tmp,edge_idx[0], dim=0)[1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a64025f1-4d3f-4207-8c63-053da27f8a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
       "          12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,   23,\n",
       "          24,   25,   26,   27,   28,   29,   30,   31,   32,   33,   34,   35,\n",
       "          36,   37,   38,   39,   40,   41,   42,   43,   44,   45,   46,   47,\n",
       "          48,   49,   50,   51,   52,   53,   54,   55,   56,   57,   58,   59,\n",
       "          60,   61,   62,   63,   64,   65,   66,   67,   68,   69,   70,   71,\n",
       "          72,   73,   74,   75,   76,   77,   78,   79,   80,   81,   82,   83,\n",
       "          84,   85,   86,   87,   88,   89,   90,   91,   92,   93,   94,   95,\n",
       "          96,   97,   98,   99,  100,  101,  102,  103,  104,  105,  106,  107,\n",
       "         108,  109,  110,  111,  112,  113,  114,  115,  116,  117,  118,  119,\n",
       "         120,  121,  122,  123,  124,  125,  126,  127,  128,  129,  130,  131,\n",
       "         132,  133,  134,  135,  136,  137,  138,  139,  140,  141,  142,  143,\n",
       "         144,  145,  146,  147,  148,  149,  150,  151,  152,  153,  154,  155,\n",
       "         156,  157,  158,  159,  160,  161,  162,  163,  164,  165,  166,  167,\n",
       "         168,  169,  170,  171,  172,  173,  174,  175,  176,  177,  178,  179,\n",
       "         180,  181,  182,  183,  184,  185,  186,  187,  188,  189,  190,  191,\n",
       "         192,  193,  194,  195,  196,  197,  198,  199,  200,  201,  202,  203,\n",
       "         204,  205,  206,  207,  208,  209,  210,  211,  212,  213,  214,  215,\n",
       "         216,  217,  218,  219,  220,  221,  222,  223,  224,  225,  226,  227,\n",
       "         228,  229,  230,  231,  232,  233,  234,  235,  236,  237,  238,  239,\n",
       "         240,  241,  242,  243,  244,  245,  246,  247,  248,  249,  250,  251,\n",
       "         252,  253,  254,  255,  256,  257,  258,  259,  260,  261,  262,  263,\n",
       "         264,  265,  266,  267,  268,  269,  270,  271,  272,  273,  274,  275,\n",
       "         276,  277,  278,  279,  280,  281,  282,  283,  284,  285,  286,  287,\n",
       "         288,  289,  290,  291,  292,  293,  294,  295,  296,  297,  298,  299,\n",
       "         300,  301,  302,  303,  304,  305,  306,  307,  308,  309,  310,  311,\n",
       "         312,  313,  314,  315,  316,  317,  318,  319,  320,  321,  322,  323,\n",
       "         324,  325,  326,  327,  328,  329,  330,  331,  332,  429,  430,  431,\n",
       "         432,  433,  434,  435,  436,  437,  438,  439,  440,  441,  442,  443,\n",
       "         444,  445,  446,  447,  448,  449,  450,  451,  452,  453,  454,  455,\n",
       "         456,  457,  458,  459,  460,  461,  462,  463,  464,  465,  466,  467,\n",
       "         468,  469,  470,  471,  472,  473,  474,  475,  476,  477,  478,  479,\n",
       "         480,  481,  482,  483,  484,  485,  486,  487,  488,  489,  490,  491,\n",
       "         492,  493,  494,  495,  496,  497,  498,  499,  500,  501,  502,  503,\n",
       "         504,  505,  506,  507,  508,  509,  510,  511,  512,  513,  514,  515,\n",
       "         516,  517,  518,  519,  520,  521,  522,  523,  524,  525,  526,  527,\n",
       "         528,  529,  530,  531,  532,  533,  534,  535,  536,  537,  538,  539,\n",
       "         540,  541,  542,  543,  544,  545,  546,  547,  548,  549,  550,  551,\n",
       "         552,  553,  554,  555,  556,  557,  558,  559,  560,  561,  562,  563,\n",
       "         564,  565,  566,  567,  568,  569,  570,  571,  572,  573,  574,  575,\n",
       "         576,  577,  578,  579,  580,  581,  582,  583,  584,  585,  586,  587,\n",
       "         588,  589,  590,  591,  592,  593,  594,  595,  596,  597,  598,  599,\n",
       "         600,  601,  602,  603,  604,  605,  606,  607,  608,  609,  610,  611,\n",
       "         612,  613,  614,  615,  616,  617,  618,  619,  620,  621,  622,  623,\n",
       "         624,  625,  626,  627,  628,  629,  630,  631,  632,  633,  634,  635,\n",
       "         636,  637,  638,  639,  640,  641,  642,  643,  644,  645,  646,  647,\n",
       "         648,  649,  650,  651,  652,  653,  654,  655,  656,  657,  658,  659,\n",
       "         660,  661,  662,  663,  664,  665,  666,  667,  668,  669,  670,  671,\n",
       "         672,  673,  674,  675,  676,  677,  678,  679,  680,  681,  682,  683,\n",
       "         684,  685,  686,  687,  688,  689,  690,  691,  692,  693,  694,  695,\n",
       "         696,  697,  698,  699,  700,  701,  702,  703,  704,  705,  706,  707,\n",
       "         708,  709,  710,  711,  712,  713,  714,  715,  716,  717,  718,  719,\n",
       "         720,  721,  722,  723,  724,  725,  726,  727,  728,  729,  730,  731,\n",
       "         732,  733,  734,  735,  736,  737,  738,  739,  740,  741,  742,  743,\n",
       "         744,  745,  746,  747,  748,  749,  750,  751,  752,  753,  754,  755,\n",
       "         756,  757,  758,  759,  760,  761,  762,  763,  764,  765,  766,  767,\n",
       "         768,  769,  770,  771,  772,  773,  774,  775,  776,  777,  778,  779,\n",
       "         780,  781,  782,  783,  784,  785,  786,  787,  788,  789,  790,  791,\n",
       "         792,  793,  794,  795,  796,  797,  798,  799,  800,  801,  802,  803,\n",
       "         804,  805,  806,  807,  808,  809,  810,  811,  812,  813,  814,  815,\n",
       "         816,  817,  818,  819,  820,  821,  822,  823,  824,  825,  826,  827,\n",
       "         828,  829,  830,  831,  832,  833,  834,  835,  836,  837,  838,  839,\n",
       "         840,  841,  842,  843,  844,  845,  846,  847,  848,  849,  850,  851,\n",
       "         852,  853,  854,  855,  856,  857,  858,  859,  860,  861,  862,  863,\n",
       "         864,  865,  866,  867,  868,  869,  870,  871,  872,  873,  874,  875,\n",
       "         876,  877,  878,  879,  880,  881,  882,  883,  884,  885,  886,  887,\n",
       "         888,  889,  890,  891,  892,  893,  894,  895,  896,  897,  898,  899,\n",
       "         900,  901,  902,  903,  904,  905,  906,  907,  908,  909,  910,  911,\n",
       "         912,  913,  914,  915,  916,  917,  918,  919,  920,  921,  922,  923,\n",
       "         924,  925,  926,  927,  928,  929,  930,  931,  932,  933,  934,  935,\n",
       "         936,  937,  938,  939,  940,  941,  942,  943,  944,  945,  946,  947,\n",
       "         948,  949,  950,  951,  952,  953,  954,  955,  956,  957,  958,  959,\n",
       "         960,  961,  962,  963,  964,  965,  966,  967,  968,  969,  970,  971,\n",
       "         972,  973,  974,  975,  976,  977,  978,  979,  980,  981,  982,  983,\n",
       "         984,  985,  986,  987,  988,  989,  990,  991,  992,  993,  994,  995,\n",
       "         996,  997,  998,  999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007,\n",
       "        1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019,\n",
       "        1020, 1021, 1022, 1023, 1024], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_idx[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57671ebc-d9a9-4fff-96ad-2f69d44ed482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024-929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2dda8cf-192d-4f3e-b3f1-032c775d7545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([929])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_idx[0].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7742d64c-58c4-43da-8007-bb4407940d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2755    96\n",
       "77       1\n",
       "1402     1\n",
       "1190     1\n",
       "2713     1\n",
       "        ..\n",
       "117      1\n",
       "119      1\n",
       "68       1\n",
       "167      1\n",
       "1996     1\n",
       "Name: count, Length: 930, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c31bdc-2ca3-489f-8d63-64adf4c2d99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2754, device='cuda:0'), tensor(2755, device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_idx.max(),newer_sampled_idx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "825eb67e-cd96-42e9-8b91-46d072ad6765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0003, device='cuda:0'), tensor(0., device='cuda:0'))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tmp.min(),val[newer_sampled_idx.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1defc5e-a441-4425-8ae1-705a62117ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1024, 2754], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_idx.max(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0a5e9333-7409-4b8e-a317-020d8f148efa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\IPython\\core\\formatters.py:711\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    704\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m    705\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[0;32m    707\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[0;32m    708\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[0;32m    709\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[0;32m    710\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[1;32m--> 711\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    712\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\IPython\\lib\\pretty.py:411\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    408\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    409\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[0;32m    410\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m--> 411\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\IPython\\lib\\pretty.py:779\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[1;32m--> 779\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\_tensor.py:461\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    458\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[0;32m    459\u001b[0m     )\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\_tensor_str.py:677\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    676\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\_tensor_str.py:597\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    595\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    596\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 597\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    600\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\_tensor_str.py:349\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    347\u001b[0m     )\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 349\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m _Formatter(\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\_tensor_str.py:385\u001b[0m, in \u001b[0;36mget_summarized_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     start \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, PRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems)]\n\u001b[0;32m    384\u001b[0m     end \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m PRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))]\n\u001b[1;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack([get_summarized_data(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4752014-9a2b-4bdd-998f-c117b9f7907c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e47441cc-87a0-4ede-9728-08261f6a65c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloudClassifier a\n",
      "PointCloudClassifier V: torch.Size([1024, 32])\n",
      "  UNet down...\n",
      "   V: torch.Size([1024, 32]) tensor(0., device='cuda:0')\n",
      "   h_target: torch.Size([103, 32]) tensor(0., device='cuda:0')\n",
      "   edge_index: torch.Size([2, 5120])\n",
      "   edge_attr: torch.Size([5120, 32]) tensor(0.0623, device='cuda:0')\n",
      "    ConvLayer edge_attr: torch.Size([5120, 32]) tensor(0.6850, device='cuda:0')\n",
      "    ConvLayer h0: torch.Size([103, 32]) tensor(0., device='cuda:0')\n",
      "    ConvLayer self.alpha: torch.Size([32]) tensor(0.8000, device='cuda:0')\n",
      "    ConvLayer out: torch.Size([103, 32]) tensor(0.6369, device='cuda:0')\n",
      "   Δh: torch.Size([103, 32]) tensor(0.6369, device='cuda:0')\n",
      "  down norm V_/std: torch.Size([103, 32]) / tensor(0., device='cuda:0')\n",
      "  UNet down...\n",
      "   V: torch.Size([103, 32]) tensor(0.6368, device='cuda:0')\n",
      "   h_target: torch.Size([26, 32]) tensor(0., device='cuda:0')\n",
      "   edge_index: torch.Size([2, 515])\n",
      "   edge_attr: torch.Size([515, 32]) tensor(0.0479, device='cuda:0')\n",
      "    ConvLayer edge_attr: torch.Size([515, 32]) tensor(0.7338, device='cuda:0')\n",
      "    ConvLayer h0: torch.Size([26, 32]) tensor(5.3973, device='cuda:0')\n",
      "    ConvLayer self.alpha: torch.Size([32]) tensor(0.8000, device='cuda:0')\n",
      "    ConvLayer out: torch.Size([26, 32]) tensor(0.7576, device='cuda:0')\n",
      "   Δh: torch.Size([26, 32]) tensor(0.7576, device='cuda:0')\n",
      "  down norm V_/std: torch.Size([26, 32]) / tensor(0.6368, device='cuda:0')\n",
      "  UNet down...\n",
      "   V: torch.Size([26, 32]) tensor(0.5894, device='cuda:0')\n",
      "   h_target: torch.Size([7, 32]) tensor(0., device='cuda:0')\n",
      "   edge_index: torch.Size([2, 130])\n",
      "   edge_attr: torch.Size([130, 32]) tensor(0.0482, device='cuda:0')\n",
      "    ConvLayer edge_attr: torch.Size([130, 32]) tensor(0.8015, device='cuda:0')\n",
      "    ConvLayer h0: torch.Size([7, 32]) tensor(6.2279, device='cuda:0')\n",
      "    ConvLayer self.alpha: torch.Size([32]) tensor(0.8000, device='cuda:0')\n",
      "    ConvLayer out: torch.Size([7, 32]) tensor(0.7697, device='cuda:0')\n",
      "   Δh: torch.Size([7, 32]) tensor(0.7697, device='cuda:0')\n",
      "  down norm V_/std: torch.Size([7, 32]) / tensor(0.5894, device='cuda:0')\n",
      "  UNet down...\n",
      "   V: torch.Size([7, 32]) tensor(0.5532, device='cuda:0')\n",
      "   h_target: torch.Size([2, 32]) tensor(0., device='cuda:0')\n",
      "   edge_index: torch.Size([2, 14])\n",
      "   edge_attr: torch.Size([14, 32]) tensor(0.0784, device='cuda:0')\n",
      "    ConvLayer edge_attr: torch.Size([14, 32]) tensor(0.8213, device='cuda:0')\n",
      "    ConvLayer h0: torch.Size([2, 32]) tensor(2.2161, device='cuda:0')\n",
      "    ConvLayer self.alpha: torch.Size([32]) tensor(0.8000, device='cuda:0')\n",
      "    ConvLayer out: torch.Size([2, 32]) tensor(0.7607, device='cuda:0')\n",
      "   Δh: torch.Size([2, 32]) tensor(0.7607, device='cuda:0')\n",
      "  down norm V_/std: torch.Size([2, 32]) / tensor(0.5532, device='cuda:0')\n",
      "  UNet up...\n",
      "    ConvLayer edge_attr: torch.Size([14, 32]) tensor(0.8993, device='cuda:0')\n",
      "    ConvLayer h0: torch.Size([7, 32]) tensor(0.8926, device='cuda:0')\n",
      "    ConvLayer self.alpha: torch.Size([32]) tensor(0.8000, device='cuda:0')\n",
      "    ConvLayer out: torch.Size([7, 32]) tensor(0.7161, device='cuda:0')\n",
      "  UNet up...\n",
      "    ConvLayer edge_attr: torch.Size([130, 32]) tensor(0.8574, device='cuda:0')\n",
      "    ConvLayer h0: torch.Size([26, 32]) tensor(3.2133, device='cuda:0')\n",
      "    ConvLayer self.alpha: torch.Size([32]) tensor(0.8000, device='cuda:0')\n",
      "    ConvLayer out: torch.Size([26, 32]) tensor(0.7803, device='cuda:0')\n",
      "  UNet up...\n",
      "    ConvLayer edge_attr: torch.Size([515, 32]) tensor(0.6840, device='cuda:0')\n",
      "    ConvLayer h0: torch.Size([103, 32]) tensor(2.4939, device='cuda:0')\n",
      "    ConvLayer self.alpha: torch.Size([32]) tensor(0.8000, device='cuda:0')\n",
      "    ConvLayer out: torch.Size([103, 32]) tensor(0.6983, device='cuda:0')\n",
      "  UNet up...\n",
      "    ConvLayer edge_attr: torch.Size([5120, 32]) tensor(0.6932, device='cuda:0')\n",
      "    ConvLayer h0: torch.Size([1024, 32]) tensor(2.6254, device='cuda:0')\n",
      "    ConvLayer self.alpha: torch.Size([32]) tensor(0.8000, device='cuda:0')\n",
      "    ConvLayer out: torch.Size([1024, 32]) tensor(0.7327, device='cuda:0')\n",
      " PointCloudClassifier V: torch.Size([1024, 32]) std: tensor(0.5862, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    out=model(e.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f654756-2fd9-4c01-ae4c-ba870e9ea7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0623,  0.0289, -0.1476,  0.6200,  0.8131, -0.2223,  0.1217, -1.0471,\n",
       "         -0.6724,  0.6702,  0.4689,  0.4061, -0.2864,  0.6696,  0.0085,  0.1255,\n",
       "          0.6218,  0.4721,  0.0220, -0.0719, -0.2046,  0.6348, -0.0732,  0.2533,\n",
       "         -0.2478, -0.4687, -0.2923,  0.9369,  0.6836, -0.8164,  0.3421,  0.1981]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fcab500-c41a-492b-aeef-967e1011c8c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 4\u001b[0m         out\u001b[38;5;241m=\u001b[39mmodel(\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m     i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch_geometric\\data\\data.py:376\u001b[0m, in \u001b[0;36mBaseData.cuda\u001b[1;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# Some PyTorch tensor like objects require a default value for `cuda`:\u001b[39;00m\n\u001b[0;32m    375\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m device\n\u001b[1;32m--> 376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch_geometric\\data\\data.py:340\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[1;32m--> 340\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch_geometric\\data\\storage.py:201\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch_geometric\\data\\storage.py:895\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[1;34m(data, func)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m--> 895\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch_geometric\\data\\data.py:376\u001b[0m, in \u001b[0;36mBaseData.cuda.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# Some PyTorch tensor like objects require a default value for `cuda`:\u001b[39;00m\n\u001b[0;32m    375\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m device\n\u001b[1;32m--> 376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    377\u001b[0m                   \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for batch in train_loader:\n",
    "    with torch.no_grad():\n",
    "        out=model(batch.cuda())\n",
    "    i-=1\n",
    "    if i<=0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08bd9452-38bd-4036-bb68-9673ffbe2b1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m      2\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\cuda\\memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9bedd3c-cb08-4acd-8d4b-54b7616d99ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 64]), DataBatch(y=[3], pos=[22973, 3], batch=[22973], ptr=[4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape,batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04e67ddd-7bb7-442c-8b83-245b93cd2943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0846,  0.2437,  0.4930,  0.5731, -0.4289, -0.3177, -1.1218, -0.4881,\n",
       "         -0.5131,  0.4151,  0.3612, -0.1624,  0.8598, -0.5200,  0.6610,  0.2913,\n",
       "          0.0747, -0.2293, -0.7240, -0.5975, -0.0671,  0.1689,  0.4994,  0.1054,\n",
       "         -0.5291,  0.6520,  0.2644,  0.6395, -0.3990,  0.2731, -0.1127, -0.9938,\n",
       "          0.1512,  0.7586,  0.0016,  0.4451,  0.4444, -0.9466, -0.0186, -0.0166,\n",
       "          0.1230, -0.1883, -0.4473,  0.1235,  0.2731, -0.4710,  0.6529, -0.8307,\n",
       "         -0.7177,  0.0408,  0.3225, -0.2626, -0.6011, -0.2693, -0.7528, -0.0079,\n",
       "         -0.2458,  0.3422, -0.1566,  0.5267,  0.0234,  0.1355, -0.2149,  0.1233],\n",
       "        [ 0.3997,  0.1986,  0.5120,  0.6227, -0.1467, -0.1928, -0.9584, -0.3459,\n",
       "         -0.4417,  0.4930,  0.1917, -0.2493,  1.0093, -0.4703,  0.4498,  0.2807,\n",
       "         -0.0018, -0.1181, -0.7682, -0.4893, -0.1825, -0.0344,  0.6766, -0.0524,\n",
       "         -0.7310,  0.5407, -0.0073,  0.6747, -0.3235,  0.3079, -0.2274, -0.8716,\n",
       "          0.2074,  0.6266,  0.1813,  0.5119,  0.3829, -0.8318, -0.0468, -0.0116,\n",
       "          0.0199,  0.0321, -0.2661, -0.0221,  0.1296, -0.3199,  0.5835, -0.5967,\n",
       "         -0.2963, -0.1770,  0.4030, -0.2218, -0.7595, -0.3536, -0.6790,  0.1991,\n",
       "         -0.0487,  0.0968, -0.1059,  0.6111,  0.3103,  0.2241, -0.2763,  0.1949],\n",
       "        [ 0.4229,  0.5062,  0.0896,  0.6342, -0.4572, -0.3191, -0.8319, -0.2337,\n",
       "         -0.3378,  0.3427,  0.1393, -0.2502,  0.7276, -0.2211,  0.7403,  0.2346,\n",
       "          0.0763, -0.3331, -0.7212, -0.5850,  0.0045, -0.3876,  0.3765, -0.1304,\n",
       "         -0.6117,  0.6958,  0.4860,  0.6722, -0.6281, -0.2079,  0.1207, -1.0933,\n",
       "         -0.0228,  1.0038,  0.1946,  0.2107,  0.6928, -1.2065,  0.3073, -0.5361,\n",
       "          0.0800,  0.0246, -0.5199,  0.2268,  0.1540, -0.6818,  0.4714, -1.0629,\n",
       "         -0.6106, -0.1180,  0.4256, -0.2795, -0.7106, -0.2572, -0.5744,  0.2041,\n",
       "         -0.1589,  0.0728,  0.1375,  0.6304, -0.4353,  0.4137,  0.0746,  0.0184]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321b71a9-427a-4399-9435-c08db50fb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c34734a6-657a-4534-b3b6-b9b25f6dbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_array(x):\n",
    "    if hasattr(x, 'clone'):\n",
    "        return x.clone()\n",
    "    elif hasattr(x, 'copy'):\n",
    "        return x.copy()\n",
    "    elif type(x).__module__.startswith(\"tensorflow\"):\n",
    "        import tensorflow as tf\n",
    "        return tf.identity(x)\n",
    "    else:\n",
    "        raise TypeError(f\"Cannot clone object of type {type(x)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44191fd-8baa-4c07-95e2-96170a9ed14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_uniform(fan_in, fan_out):\n",
    "    \"\"\"Xavier/Glorot Uniform Initialization\"\"\"\n",
    "    limit = np.sqrt(6 / (fan_in + fan_out))\n",
    "    return np.random.uniform(-limit, limit, size=(fan_in, fan_out))\n",
    "\n",
    "def xavier_normal(fan_in, fan_out):\n",
    "    \"\"\"Xavier/Glorot Normal Initialization\"\"\"\n",
    "    std = np.sqrt(2 / (fan_in + fan_out))\n",
    "    return np.random.randn(fan_in, fan_out) * std\n",
    "\n",
    "def he_uniform(fan_in, fan_out):\n",
    "    \"\"\"He Uniform Initialization (for ReLU)\"\"\"\n",
    "    limit = np.sqrt(6 / fan_in)\n",
    "    return np.random.uniform(-limit, limit, size=(fan_in, fan_out))\n",
    "\n",
    "def he_normal(fan_in, fan_out):\n",
    "    \"\"\"He Normal Initialization (for ReLU)\"\"\"\n",
    "    std = np.sqrt(2 / fan_in)\n",
    "    return np.random.randn(fan_in, fan_out) * std\n",
    "\n",
    "def init_linear_layer(fan_in, fan_out, method='he_normal'):\n",
    "    if method == 'he_normal':\n",
    "        W = he_normal(fan_in, fan_out)\n",
    "    elif method == 'he_uniform':\n",
    "        W = he_uniform(fan_in, fan_out)\n",
    "    elif method == 'xavier_normal':\n",
    "        W = xavier_normal(fan_in, fan_out)\n",
    "    elif method == 'xavier_uniform':\n",
    "        W = xavier_uniform(fan_in, fan_out)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown init method\")\n",
    "    \n",
    "    b = np.zeros(fan_out)  # Standard to init biases to zero\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac478227-6a3e-4a9f-825a-86c2d823358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SELU(x):\n",
    "    L=1.0507\n",
    "    A=1.6733\n",
    "    y=clone_array(x)\n",
    "    y[y>0]=L*y[y>0]\n",
    "    y[y<=0]=L*A*((y[y<=0]).exp()-1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "427a11d1-4e96-4ab7-b0b5-f3580d8db179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    y=clone_array(x)\n",
    "    y[y<=0]=0\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dfd7cb6-4b3e-4994-b29e-84ca315fec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SiLU(x):\n",
    "    return x*(1/(-x).exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48eea944-3520-4fda-a912-40ff33b04a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.exp>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(2).exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56260a33-4552-48bb-8c15-7fbb9d6ce762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 std: 1.0115141868591309\n",
      "Layer 2 std: 1.0234248638153076\n",
      "Layer 3 std: 1.022629976272583\n",
      "Layer 4 std: 0.9998650550842285\n",
      "Layer 5 std: 0.9679993987083435\n",
      "Layer 6 std: 1.0320063829421997\n",
      "Layer 7 std: 0.9962770938873291\n",
      "Layer 8 std: 0.9833673238754272\n",
      "Layer 9 std: 1.0106019973754883\n",
      "Layer 10 std: 0.987510085105896\n",
      "Layer 11 std: 0.970865786075592\n",
      "Layer 12 std: 0.922020673751831\n",
      "Layer 13 std: 1.0506401062011719\n",
      "Layer 14 std: 1.1412053108215332\n",
      "Layer 15 std: 1.1503292322158813\n",
      "Layer 16 std: 1.0887736082077026\n",
      "Layer 17 std: 1.0316565036773682\n",
      "Layer 18 std: 1.0803827047348022\n",
      "Layer 19 std: 1.0234907865524292\n",
      "Layer 20 std: 1.0064483880996704\n",
      "Layer 21 std: 1.0660984516143799\n",
      "Layer 22 std: 1.1832232475280762\n",
      "Layer 23 std: 1.2145192623138428\n",
      "Layer 24 std: 1.2397723197937012\n",
      "Layer 25 std: 1.1366950273513794\n",
      "Layer 26 std: 1.0359729528427124\n",
      "Layer 27 std: 0.9909015893936157\n",
      "Layer 28 std: 1.0834981203079224\n",
      "Layer 29 std: 1.097040057182312\n",
      "Layer 30 std: 1.0451890230178833\n",
      "Layer 31 std: 0.9502233862876892\n",
      "Layer 32 std: 0.890515148639679\n",
      "Layer 33 std: 0.8540569543838501\n",
      "Layer 34 std: 0.8544186353683472\n",
      "Layer 35 std: 0.9395029544830322\n",
      "Layer 36 std: 0.9486273527145386\n",
      "Layer 37 std: 0.9911968111991882\n",
      "Layer 38 std: 0.8814086318016052\n",
      "Layer 39 std: 0.967110276222229\n",
      "Layer 40 std: 1.0214685201644897\n",
      "Layer 41 std: 0.9767132997512817\n",
      "Layer 42 std: 0.8765257000923157\n",
      "Layer 43 std: 0.8856367468833923\n",
      "Layer 44 std: 0.8574038147926331\n",
      "Layer 45 std: 0.893946647644043\n",
      "Layer 46 std: 0.8467156291007996\n",
      "Layer 47 std: 0.9052826166152954\n",
      "Layer 48 std: 0.8849630355834961\n",
      "Layer 49 std: 0.9403788447380066\n",
      "Layer 50 std: 0.9622048735618591\n",
      "Layer 51 std: 0.947064995765686\n",
      "Layer 52 std: 0.9785986542701721\n",
      "Layer 53 std: 1.0076433420181274\n",
      "Layer 54 std: 1.1207722425460815\n",
      "Layer 55 std: 1.1140892505645752\n",
      "Layer 56 std: 1.090101718902588\n",
      "Layer 57 std: 1.1696444749832153\n",
      "Layer 58 std: 1.1683430671691895\n",
      "Layer 59 std: 1.1362946033477783\n",
      "Layer 60 std: 1.0860710144042969\n",
      "Layer 61 std: 1.067500352859497\n",
      "Layer 62 std: 1.023863434791565\n",
      "Layer 63 std: 0.9627070426940918\n",
      "Layer 64 std: 0.9423915147781372\n",
      "Layer 65 std: 0.9729244112968445\n",
      "Layer 66 std: 1.0560836791992188\n",
      "Layer 67 std: 0.9449977278709412\n",
      "Layer 68 std: 1.0171363353729248\n",
      "Layer 69 std: 1.0060995817184448\n",
      "Layer 70 std: 1.053124189376831\n",
      "Layer 71 std: 1.1597216129302979\n",
      "Layer 72 std: 1.1726186275482178\n",
      "Layer 73 std: 1.1642524003982544\n",
      "Layer 74 std: 1.0950952768325806\n",
      "Layer 75 std: 1.018472671508789\n",
      "Layer 76 std: 0.9316315054893494\n",
      "Layer 77 std: 0.8763181567192078\n",
      "Layer 78 std: 0.88376784324646\n",
      "Layer 79 std: 0.93387371301651\n",
      "Layer 80 std: 0.9245019555091858\n",
      "Layer 81 std: 0.9440272450447083\n",
      "Layer 82 std: 0.882695734500885\n",
      "Layer 83 std: 0.9048241376876831\n",
      "Layer 84 std: 1.0337833166122437\n",
      "Layer 85 std: 1.0672011375427246\n",
      "Layer 86 std: 1.1278988122940063\n",
      "Layer 87 std: 1.0156888961791992\n",
      "Layer 88 std: 1.1049931049346924\n",
      "Layer 89 std: 1.0363810062408447\n",
      "Layer 90 std: 0.8985241651535034\n",
      "Layer 91 std: 0.8629513382911682\n",
      "Layer 92 std: 0.9090154767036438\n",
      "Layer 93 std: 0.9313637614250183\n",
      "Layer 94 std: 0.9346490502357483\n",
      "Layer 95 std: 0.9276896715164185\n",
      "Layer 96 std: 0.9332424998283386\n",
      "Layer 97 std: 1.0592341423034668\n",
      "Layer 98 std: 0.9845116138458252\n",
      "Layer 99 std: 0.9634708166122437\n",
      "Layer 100 std: 0.9373738765716553\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.init import kaiming_uniform_, xavier_normal_, xavier_uniform_\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "dim = 32\n",
    "depth = 100\n",
    "x = torch.randn(100, dim).cuda()\n",
    "\n",
    "layers = []\n",
    "\n",
    "for _ in range(depth):\n",
    "    layer = nn.Linear(dim, dim, bias=False).cuda()\n",
    "    xavier_uniform_(layer.weight)  # apply proper init\n",
    "    layers.append(layer)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    for i, layer in enumerate(layers):\n",
    "        act=nn.functional.selu\n",
    "        x = act(layer(x))#.relu()*1.03\n",
    "        #/print(f'Layer {i+1} std: {x.std().cpu().numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4fbe4-293b-463a-a6c0-ac37319d56b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
